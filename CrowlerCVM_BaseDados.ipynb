{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Python\\CodigosTrabalho\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Importação de bibliotecas necessárias para diversas funções\n",
    "from bs4 import BeautifulSoup  # Utilizado para parsing de documentos HTML e XML\n",
    "import requests  # Utilizado para fazer requisições HTTP\n",
    "import html5lib  # Parser para documentos HTML e XML\n",
    "import os  # Utilizado para interagir com o sistema operacional\n",
    "from dateutil.relativedelta import relativedelta  # Utilizado para cálculos de diferenças de datas\n",
    "import pandas as pd  # Utilizado para manipulação e análise de dados\n",
    "import numpy as np  # Utilizado para cálculos numéricos\n",
    "import pyarrow.parquet as pq  # Utilizado para leitura e escrita de dados em formato Parquet\n",
    "import pyarrow as pa  # Utilizado para manipulação de dados com Apache Arrow\n",
    "import pyarrow.dataset as ds  # Utilizado para manipulação de datasets com Apache Arrow\n",
    "import pyarrow.compute as pc  # Utilizado para computação de funções com Apache Arrow\n",
    "from urllib.request import urlopen  # Utilizado para abrir URLs\n",
    "from io import BytesIO  # Utilizado para manipulação de fluxos de bytes\n",
    "from zipfile import ZipFile  # Utilizado para manipulação de arquivos zip\n",
    "from datetime import datetime  # Utilizado para manipulação de datas e horas\n",
    "import warnings  # Utilizado para gerenciar avisos em Python\n",
    "\n",
    "# Ignorar avisos de RankingWarning do numpy\n",
    "warnings.simplefilter('ignore', np.RankWarning)\n",
    "\n",
    "# Configuração do nível de logging para INFO\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# Desabilitar a verificação SSL para requests ao definir a variável de ambiente 'verify' como \"False\"\n",
    "# Nota: Desabilitar a verificação SSL não é recomendado para produção devido a riscos de segurança.\n",
    "os.environ['verify'] = \"False\"\n",
    "\n",
    "# Faz uma requisição HTTP para o Google com a verificação SSL desabilitada\n",
    "requests.get('https://www.google.com', verify=False)\n",
    "\n",
    "# Definição das URLs para dados históricos de fundos de investimento disponibilizados pela CVM\n",
    "URL_HIS_FI_NEW_YEARS = 'https://dados.cvm.gov.br/dados/FI/DOC/CDA/DADOS/'\n",
    "URL_HIS_FI_OLD_YEARS = 'https://dados.cvm.gov.br/dados/FI/DOC/CDA/DADOS/HIST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\Python\\CodigosTrabalho\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dados.cvm.gov.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rodrigo\\Python\\CodigosTrabalho\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dados.cvm.gov.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Ler um dataset existente do diretório especificado usando Apache Arrow\n",
    "dataset = ds.dataset(r'C:\\Users\\Rodrigo\\Python\\PythonCVM\\CarteirasCVMParquet')\n",
    "\n",
    "# Fazer requisição HTTP para obter dados dos anos recentes de fundos de investimento da CVM\n",
    "request_new_years = requests.get(URL_HIS_FI_NEW_YEARS, verify=False)\n",
    "\n",
    "# Fazer requisição HTTP para obter dados dos anos antigos de fundos de investimento da CVM\n",
    "request_old_years = requests.get(URL_HIS_FI_OLD_YEARS, verify=False)\n",
    "\n",
    "# Analisar o conteúdo HTML da resposta HTTP para os dados recentes usando BeautifulSoup\n",
    "soup_new_years = BeautifulSoup(request_new_years.content, features='html5lib')\n",
    "\n",
    "# Analisar o conteúdo HTML da resposta HTTP para os dados antigos usando BeautifulSoup\n",
    "soup_old_years = BeautifulSoup(request_old_years.content, features='html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a data de início do histórico de dados\n",
    "DATE_INI = '2005-01-01'\n",
    "\n",
    "# Calcular a data atual adicionando um mês à data de hoje e formatar no formato 'MM-YYYY'\n",
    "CURRENT_DATE = pd.to_datetime(datetime.today() + relativedelta(months=1)).strftime('%m-%Y')\n",
    "\n",
    "# Buscar dados na CVM\n",
    "# Cria uma faixa de datas mensais desde a data de início até a data atual e formata como 'YYYYMM'\n",
    "date = pd.date_range(start=str(DATE_INI), end=str(CURRENT_DATE), freq='M').strftime('%Y%m')\n",
    "\n",
    "# Cria uma lista dos anos únicos dentro da faixa de datas mensais desde a data de início até a data atual\n",
    "years = list(pd.date_range(start=str(DATE_INI), end=str(CURRENT_DATE), freq='M').strftime('%Y').unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa uma lista para armazenar os anos disponíveis na CVM\n",
    "years_cvm = []\n",
    "\n",
    "# Itera sobre todos os links encontrados na página HTML de dados antigos\n",
    "for link in soup_old_years.find_all('a'):\n",
    "    # Verifica se o comprimento do atributo 'href' do link é igual a 15\n",
    "    if len(link.get('href')) == 15:\n",
    "        # Extrai os anos do atributo 'href' e adiciona à lista 'years_cvm'\n",
    "        years_cvm.append(link.get('href')[7:11])\n",
    "\n",
    "# Filtra os anos para incluir apenas aqueles maiores ou iguais ao menor ano na lista 'years'\n",
    "year_filter = list(filter(lambda score: score >= min(years), years_cvm))\n",
    "\n",
    "# Exibe a lista de anos filtrados\n",
    "year_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para mapear tipos de dados do Pandas para tipos de dados do PyArrow\n",
    "def pandas_to_pyarrow_dtype(dtype):\n",
    "    # Verifica se o tipo de dados do Pandas é um tipo inteiro\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return pa.int64()  # Retorna o tipo de dados inteiro de 64 bits do PyArrow\n",
    "    # Verifica se o tipo de dados do Pandas é um tipo float\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return pa.float64()  # Retorna o tipo de dados float de 64 bits do PyArrow\n",
    "    # Verifica se o tipo de dados do Pandas é uma string\n",
    "    elif pd.api.types.is_string_dtype(dtype):\n",
    "        return pa.string()  # Retorna o tipo de dados string do PyArrow\n",
    "    # Verifica se o tipo de dados do Pandas é um tipo datetime\n",
    "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "        return pa.timestamp('ns')  # Retorna o tipo de dados timestamp (nanosegundos) do PyArrow\n",
    "    # Lança uma exceção se o tipo de dados do Pandas não for suportado\n",
    "    else:\n",
    "        raise ValueError(f\"tipo de dados Pandas não suportado: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formatação tipo de dado DataFrame\n",
    "def trataFormato(df_inf_raw):\n",
    "    df_inf_raw['QT_VENDA_NEGOC'] = df_inf_raw['QT_VENDA_NEGOC'].astype(float)\n",
    "    df_inf_raw['VL_VENDA_NEGOC'] = df_inf_raw['VL_VENDA_NEGOC'].astype(float)\n",
    "    df_inf_raw['QT_AQUIS_NEGOC'] = df_inf_raw['QT_AQUIS_NEGOC'].astype(float)\n",
    "    df_inf_raw['VL_AQUIS_NEGOC'] = df_inf_raw['VL_AQUIS_NEGOC'].astype(float)\n",
    "    df_inf_raw['QT_POS_FINAL'] = df_inf_raw['QT_POS_FINAL'].astype(float)\n",
    "    df_inf_raw['VL_MERC_POS_FINAL'] = df_inf_raw['VL_MERC_POS_FINAL'].astype(float)\n",
    "    df_inf_raw['VL_CUSTO_POS_FINAL'] = df_inf_raw['VL_CUSTO_POS_FINAL'].astype(float)\n",
    "    df_inf_raw['DT_VENC'] = df_inf_raw['DT_VENC'].astype(pd.StringDtype())\n",
    "    try:\n",
    "        df_inf_raw['INVEST_COLETIVO_GESTOR'] = df_inf_raw['INVEST_COLETIVO_GESTOR'].astype(pd.StringDtype())\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        df_inf_raw['INVEST_COLETIVO'] = df_inf_raw['INVEST_COLETIVO'].astype(pd.StringDtype())\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        df_inf_raw['PR_INDEXADOR_POSFX'] = df_inf_raw['PR_INDEXADOR_POSFX'].astype(float)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        df_inf_raw['PR_CUPOM_POSFX'] = df_inf_raw['PR_CUPOM_POSFX'].astype(float)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        df_inf_raw['PR_TAXA_PREFX'] = df_inf_raw['PR_TAXA_PREFX'].astype(float)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        df_inf_raw['QT_ATIVO_EXTERIOR'] = df_inf_raw['QT_ATIVO_EXTERIOR'].astype(float)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        df_inf_raw['VL_ATIVO_EXTERIOR'] = df_inf_raw['VL_ATIVO_EXTERIOR'].astype(float)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        df_inf_raw['CD_BV_MERC'] = df_inf_raw['CD_BV_MERC'].astype(pd.StringDtype())\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        df_inf_raw['CD_ATIVO_BV_MERC'] = df_inf_raw['CD_ATIVO_BV_MERC'].astype(pd.StringDtype())\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        df_inf_raw['AG_RISCO'] = df_inf_raw['AG_RISCO'].astype(pd.StringDtype())\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        df_inf_raw['DT_RISCO'] = df_inf_raw['DT_RISCO'].astype(pd.StringDtype())\n",
    "    except Exception:\n",
    "        pass\n",
    "    return df_inf_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baixando carteiras até o ano que a CVM passa abrir por nès encoding - 'utf-8'\n",
    "df_inf_raw = pd.DataFrame()\n",
    "logging.info('Anos Pasta HIST: {}. '.format(year_filter))\n",
    "for year in year_filter:\n",
    "    url = 'https://dados.cvm.gov.br/dados/FI/DOC/CDA/DADOS/HIST/cda_fi_'+year+'.zip'\n",
    "    logging.info('Obtendo dados do Ano: {}.'.format(year))\n",
    "    with ZipFile(BytesIO(urlopen(url).read())) as myzip:\n",
    "        num = 1\n",
    "        while num < 20:\n",
    "            try:\n",
    "                with myzip.open('cda_fi_BLC_' + str(num) + '_' + year+'.csv') as myfile:\n",
    "                    df_inf_raw = pd.concat([df_inf_raw, pd.read_csv(myfile, encoding = 'latin1', engine = 'python', on_bad_lines='skip', sep=';',decimal=',')])\n",
    "            except Exception:\n",
    "                pass\n",
    "            num +=1\n",
    "    \n",
    "    df_inf_raw = trataFormato(df_inf_raw)\n",
    "\n",
    "    #criar o schema PyArrow a partir dos dtypes do DataFrame\n",
    "    schema = pa.schema([(col, pandas_to_pyarrow_dtype(df_inf_raw[col].dtype)) for col in df_inf_raw.columns])\n",
    "    \n",
    "    #Convertendo os dados em tabela pyArrow\n",
    "    novos_dados_table = pa.Table.from_pandas(df_inf_raw, schema=schema)\n",
    "    \n",
    "    #Escrevendo os novos dados em um novo arquivo Parquet no dataset\n",
    "    pq.write_to_dataset(novos_dados_table,root_path=r'C:\\Users\\Rodrigo\\Python\\PythonCVM\\CarteirasCVMParquet')\n",
    "    novos_dados_table = novos_dados_table[0:0]\n",
    "    df_inf_raw = df_inf_raw[0:0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baixando carteiras mensais até faltar 6 meses\n",
    "datas = []\n",
    "df_inf_raw = pd.DataFrame()\n",
    "for link in soup_new_years.find_all('a'):\n",
    "     if len(link.get('href')) == 17:\n",
    "         datas.append(link.get('href')[7:13])\n",
    "logging.info('Meses Recentes: {}. '.format(datas))\n",
    "meses_cvm = len(datas)\n",
    "i=0\n",
    "for dt in datas:\n",
    "    print(dt)\n",
    "    if i< meses_cvm - 6:\n",
    "        url = 'https://dados.cvm.gov.br/dados/FI/DOC/CDA/DADOS/cda_fi_'+dt+'.zip'\n",
    "        with ZipFile(BytesIO(urlopen(url).read())) as myzip:\n",
    "            num = 1\n",
    "            while num < 20:\n",
    "                try:\n",
    "                    with myzip.open('cda_fi_BLC_' + str(num) + '_' + dt + '.csv') as myfile:\n",
    "                        df_inf_raw = pd.concat([df_inf_raw, pd.read_csv(myfile, encoding = 'latin1', sep=\";\" ,decimal=\",\")])\n",
    "                except Exception:\n",
    "                    pass\n",
    "                num+=1\n",
    "        \n",
    "        df_inf_raw['QT_VENDA_NEGOC'] = df_inf_raw['QT_VENDA_NEGOC'].astype(float)\n",
    "        df_inf_raw['VL_VENDA_NEGOC'] = df_inf_raw['VL_VENDA_NEGOC'].astype(float)\n",
    "        df_inf_raw['QT_AQUIS_NEGOC'] = df_inf_raw['QT_AQUIS_NEGOC'].astype(float)\n",
    "        df_inf_raw['VL_AQUIS_NEGOC'] = df_inf_raw['VL_AQUIS_NEGOC'].astype(float)\n",
    "        df_inf_raw['QT_POS_FINAL'] = df_inf_raw['QT_POS_FINAL'].astype(float)\n",
    "        df_inf_raw['VL_MERC_POS_FINAL'] = df_inf_raw['VL_MERC_POS_FINAL'].astype(float)\n",
    "        df_inf_raw['VL_CUSTO_POS_FINAL'] = df_inf_raw['VL_CUSTO_POS_FINAL'].astype(float)\n",
    "        df_inf_raw['DT_VENC'] = df_inf_raw['DT_VENC'].astype(pd.StringDtype())\n",
    "        try:\n",
    "            df_inf_raw['INVEST_COLETIVO_GESTOR'] = df_inf_raw['INVEST_COLETIVO_GESTOR'].astype(pd.StringDtype())\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            df_inf_raw['INVEST_COLETIVO'] = df_inf_raw['INVEST_COLETIVO'].astype(pd.StringDtype())\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            df_inf_raw['PR_INDEXADOR_POSFX'] = df_inf_raw['PR_INDEXADOR_POSFX'].astype(float)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            df_inf_raw['PR_CUPOM_POSFX'] = df_inf_raw['PR_CUPOM_POSFX'].astype(float)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            df_inf_raw['PR_TAXA_PREFX'] = df_inf_raw['PR_TAXA_PREFX'].astype(float)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            df_inf_raw['QT_ATIVO_EXTERIOR'] = df_inf_raw['QT_ATIVO_EXTERIOR'].astype(float)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            df_inf_raw['VL_ATIVO_EXTERIOR'] = df_inf_raw['VL_ATIVO_EXTERIOR'].astype(float)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            df_inf_raw['CD_BV_MERC'] = df_inf_raw['CD_BV_MERC'].astype(pd.StringDtype())\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            df_inf_raw['CD_ATIVO_BV_MERC'] = df_inf_raw['CD_ATIVO_BV_MERC'].astype(pd.StringDtype())\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            df_inf_raw['AG_RISCO'] = df_inf_raw['AG_RISCO'].astype(pd.StringDtype())\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            df_inf_raw['DT_RISCO'] = df_inf_raw['DT_RISCO'].astype(pd.StringDtype())\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            df_inf_raw['GRAU_RISCO'] = df_inf_raw['GRAU_RISCO'].astype(pd.StringDtype())\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            df_inf_raw['DS_ATIVO_EXTERIOR'] = df_inf_raw['DS_ATIVO_EXTERIOR'].astype(pd.StringDtype())\n",
    "        except Exception:\n",
    "            pass   \n",
    "\n",
    "        #criar o schema PyArrow a partir dos dtypes do Datarrame\n",
    "        schema = pa.schema([(col, pandas_to_pyarrow_dtype(df_inf_raw[col].dtype)) for col in df_inf_raw.columns])\n",
    "        \n",
    "        #Convertendo os dados em tabela pyArrow\n",
    "        novos_dados_table = pa.Table.from_pandas(df_inf_raw, schema=schema)\n",
    "        \n",
    "        #Escrevendo os novos dados em um novo arquivo Parquet no dataset\n",
    "        pq.write_to_dataset (novos_dados_table, root_path=r'C:\\Users\\Rodrigo\\Python\\PythonCVM\\CarteirasCVMParquet')\n",
    "        novos_dados_table = novos_dados_table[0:0]\n",
    "        df_inf_raw = df_inf_raw[0:0]\n",
    "        i=i+1         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_INI = '2005-01' #Data de início do Histórico\n",
    "CURRENT_DATE = pd.to_datetime(datetime.today() + relativedelta(months=1)).strftime('%m-%Y')\n",
    "\n",
    "##Buscar Dados na CVM\n",
    "date = pd.date_range(start=str(DATE_INI), end=str(CURRENT_DATE), freq='M').strftime('%Y%m')\n",
    "years = list(pd.date_range(start=str(DATE_INI), end=str(CURRENT_DATE), freq='M').strftime('%Y').unique())\n",
    "years_cvm = []\n",
    "for link in soup_old_years.find_all('a'):\n",
    "    if len(link.get('href')) == 15:\n",
    "        years_cvm.append(link.get('href')[7:11])\n",
    "year_filter = (list(filter(lambda score: score >= min(years), years_cvm)))\n",
    "year_filter\n",
    "\n",
    "#Baixando PL dos fundos até o ano que a CVM passa abrir por mês\n",
    "encoding = 'utf-8'\n",
    "df_int_raw = pd.DataFrame()\n",
    "logging.info('Anos Pasta HIST: {}. '.format(year_filter))\n",
    "for year in year_filter:\n",
    "    url = 'https://dados.cvm.gov.br/dados/FI/DOC/CDA/DADOS/HIST/cda_fi_'+year+'.zip'\n",
    "    logging.info('Obtendo dados do Ano: {}.'.format(year))\n",
    "    with ZipFile(BytesIO(urlopen(url).read())) as myzip:\n",
    "        with myzip.open('cda_fi_PL_'+year+'.csv') as myfile:\n",
    "            df_inf_raw = pd.concat([df_inf_raw, pd.read_csv(myfile, encoding = 'latin1', engine = 'python', on_bad_lines='skip', sep=';',decimal=',')])\n",
    "    \n",
    "    df_inf_raw['VL_PATRIM_LIQ'] = df_inf_raw['VL_PATRIM_LIQ'].astype(float)\n",
    "    \n",
    "    #criar o schema PyArrow a partir dos dtypes do bataFrame\n",
    "    schema = pa.schema([(col, pandas_to_pyarrow_dtype(df_inf_raw[col].dtype)) for col in df_inf_raw.columns])\n",
    "    \n",
    "    #Convertendo os dados em tabela pyArrow\n",
    "    novos_dados_table = pa.Table.from_pandas(df_inf_raw, schema=schema)\n",
    "\n",
    "    #Escrevendo os novos dados em um novo arquivo Parquet no dataset\n",
    "    pq.write_to_dataset(novos_dados_table, root_path=r'C:\\Users\\Rodrigo\\Python\\PythonCVM\\PLsCVMParquet')\n",
    "    novos_dados_table = novos_dados_table[0:0]\n",
    "    df_inf_raw = df_inf_raw[0:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baixando PLs mensais até faltar 6 meses\n",
    "datas = []\n",
    "df_inf_raw = pd.DataFrame()\n",
    "for link in soup_new_years.find_all('a'):\n",
    "\n",
    "    if len(link.get('href')) == 17:\n",
    "        datas.append(link.get('href')[7:13])\n",
    "logging.info('Meses Recentes: {}. '.format(datas))\n",
    "meses_cvm = len(datas)\n",
    "i=0\n",
    "for dt in datas:\n",
    "    if i < meses_cvm - 6:\n",
    "        url = 'https://dados.cvm.gov.br/dados/FI/DOC/CDA/DADOS/cda_fi_'+dt+'.zip'\n",
    "        with ZipFile(BytesIO(urlopen(url).read())) as myzip:\n",
    "            with myzip.open('cda_fi_PL_'+dt+'.csv') as myfile:\n",
    "                df_inf_raw = pd.concat([df_inf_raw, pd.read_csv(myfile, encoding = 'latin1', sep=\";\",decimal=\",\")])\n",
    "        \n",
    "        df_inf_raw['VL_PATRIM LIQ'] = df_inf_raw[ 'VL_PATRIM_LIQ'].astype(float)\n",
    "        \n",
    "        #criar o schema pyArrow a pandas a partir dos dtypes da DataFrame\n",
    "        schema = pa.schema([(col,pandas_to_pyarrow_dtype(df_inf_raw[col].dtype)) for col in df_inf_raw.columns])\n",
    "\n",
    "        #Convertendo os dados em tabela pyArrow\n",
    "        novos_dados_table = pa.Table.from_pandas(df_inf_raw, schema=schema)\n",
    "        \n",
    "        #Escrevendo os novos dados em um novo arquivo Parquet no dataset\n",
    "        pq.write_to_dataset(novos_dados_table,root_path=r'C:\\Users\\Rodrigo\\Python\\PythonCVM\\PLsCVMParquet')\n",
    "        novos_dados_table = novos_dados_table[0:0]\n",
    "        df_inf_raw = df_inf_raw[0:0]\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_expression = ((ds.field('CNPJ_FUNDO') == '18.255.230/0001-67') | (ds.field('CNPJ_FUNDO') == '18.272.304/0001-73') | (ds.field('CNPJ_FUNDO') == '05.471.940/0001-82') | (ds.field('CNPJ_FUNDO') == '05.464.917/0001-60') | \n",
    "(ds.field('CNPJ_FUNDO') == '05.464.917/0001-60') | (ds.field('CNPJ_FUNDO') == '05.464.914/0001-27') | (ds.field('CNPJ_FUNDO') == '05.464.914/0001-27') | (ds.field('CNPJ_FUNDO') == '05.464.910/0001-49') |\n",
    "(ds.field('CNPJ_FUNDO') == '09.613.212/0001-19') | (ds.field('CNPJ_FUNDO') == '18.255.509/0001-40') | (ds.field('CNPJ_FUNDO') == '11.110.937/0001-36') | (ds.field('CNPJ_FUNDO') == '54.438.899/0001-58') \n",
    "| (ds.field('CNPJ_FUNDO') == '39.586.784/0001-17') | (ds.field('CNPJ_FUNDO') == '40.142.095/0001-00')  | (ds.field('CNPJ_FUNDO') == '49.920.190/0001-54'))\n",
    "dataset = ds.dataset(r'C:\\Users\\Rodrigo\\Python\\PythonCVM\\CarteirasCVMParquet')\n",
    "tabelacomp = dataset.to_table(filter=filter_expression)\n",
    "\n",
    "df_filtrado = tabelacomp.to_pandas()\n",
    "df_filtrado\n",
    "df_filtrado.to_excel(r'C:\\Users\\Rodrigo\\Python\\PythonCVM\\Estudos\\teste.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_expression = (ds.field('CNPJ_FUNDO') == '41.902.409/0001-80')\n",
    "dataset = ds.dataset(r'C:\\Users\\Rodrigo\\Python\\PythonCVM\\PLsCVMParquet')\n",
    "tabelacomp = dataset.to_table(filter=filter_expression)\n",
    "df_filtrado = tabelacomp.to_pandas()\n",
    "df_filtrado.to_excel(r'C:\\Users\\Rodrigo\\Python\\PythonCVM\\Estudos\\teste2.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
